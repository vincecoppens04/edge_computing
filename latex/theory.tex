\section{Edge computing architectures}

Edge Computing is a distributed model of information processing in which data is analyzed and acted upon as close as possible to its source of generation. This strategic decentralization minimizes reliance on distant data centers, establishing localized computational, storage and control capabilities near sensors, machines, or user endpoints. The resulting architectural advantage is twofold: a dramatic reduction in latency, essential for time-critical applications, and optimization of bandwidth, achieved by filtering and aggregating massive raw datasets locally. 
Beyond pure performance, Edge systems are fundamental to ensuring service reliance in mobile intermittently connected environments and enhancing security by enabling local anonymization and preprocessing of sensitive information before any upstream transmission. Edge architectures therefore function not merely as cloud extensions, but as autonomous computing nodes capable of independent, real-time decision making~\cite{fsp-edge-computing, techtarget-edge-computing, azure-edge-dictionary}. 

\subsection{The three-layer model: From device to cloud}

A typical edge architecture is structured into three functional layers: the Device layer, the Edge layer and the Cloud layer. This hierarchy ensures that computing power and responsibilities are optimally distributed across the network continuum (Figure~\ref{fig:theory-architecture})~\cite{gfg-edge-computing, wallarm-edge-architecture}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/Theory2.jpg}
  \caption{Edge Computing Architecture. Source: Wallarm}
  \label{fig:theory-architecture}
\end{figure}

At the Device layer, sensors and controllers in phones, vehicles, or industrial equipment generate continuous data flows. These devices are small, energy-constrained, and often mobile, yet they form the foundation of the system. In industrial contexts, where specialized input/output interfaces are designed for monitoring and controlling industrial equipment, these often include Programmable Logic Controllers (PLCs)~\cite{pratexo-edge-vs-plc} coordinated by Supervisory Control Data Acquisition (SCADA) networks. These components not only collect data but can also execute control actions through actuators, enabling real-time adjustments within industrial processes~\cite{cseicon-edge-scada}.

The Edge Cloud forms the true computational heart of modern edge architectures. It sits between the local network and the wider internet, where vast volumes of sensor and application data are generated. As AI-driven systems increasingly rely on real-time analysis, image recognition, anomaly detection, predictive maintenance, the traditional model of sending all raw data to the cloud becomes inefficient and unsustainable. By processing these streams locally, the Edge Cloud drastically reduces latency and bandwidth consumption while enabling immediate, context-aware decisions. This layer typically consists of lightweight servers or gateways that combine data aggregation with localized intelligence. The growing importance of this tier has also inspired related paradigms such as Fog Computing~\cite{gfg-edge-vs-fog} (cloud-like functionality extended closer to the network edge) and Mist Computing~\cite{radiocrafts-cloud-fog-mist} (tiny-scale intelligence embedded directly into sensor devices), but it is within the Edge Cloud that most current innovation and “intelligence at the edge” truly takes place.

Finally, the Cloud Layer provides global coordination, long-term data warehousing, training of complex AI models, and remote orchestration services. Data flowing from Edge to Cloud is referred to as North-Bound traffic (typically filtered alerts or aggregated summaries), while configuration updates and commands flow back via South-Bound traffic. Communication between individual Edge nodes is termed East-West communication, often critical for machine-to-machine coordination on a factory floor~\cite{dananjaya-traffic-directions}.

\subsection{The Software Backbone: Virtualization and Orchestration}

The operational efficiency of the Edge Layer relies heavily on its software structure. It is typically modular, separating low-level control from application logic to improve maintainability and resilience. Due to resource constraints and the demand for rapid, consistent deployment across heterogeneous hardware, Container Virtualization (e.g., Docker) has become essential~\cite{ibm-containers-vs-vms}. Containers encapsulate applications and dependencies without requiring a full guest operating system (unlike traditional Virtual Machines), making them lightweight, fast to deploy, and ensuring identical behavior on a small device like a Raspberry Pi (Device/Edge) or a powerful cloud server.

Managing a fleet of containerized services is handled by an Orchestration platform like Kubernetes~\cite{lf-edge-kubernetes} (or its lightweight variants such as K3d~\cite{k3s-docs}). The orchestrator is crucial for automated deployment, scaling, failover management, and resource allocation across the distributed Edge nodes. This principle of modularity and isolation is key to maintaining resilience and enabling reliable updates (e.g., rollback mechanisms after failed updates).

\section{Communication and connectivity in edge architectures}

Effective communication within the Edge continuum requires protocols tailored for low-bandwidth and high-reliability environments, built upon the layered logic of the OSI model.

\subsection{Application layer protocols for the edge}

At the application layer, Message Queuing Telemetry Transport (MQTT) is the defining protocol for data exchange across edge environments. Unlike synchronous request–response models such as HTTP, MQTT operates on a lightweight publish–subscribe mechanism coordinated by a central broker. This design decouples data producers and consumers, minimizing communication overhead and enabling efficient, event-driven data flow among thousands of constrained devices. Within the OSI model, MQTT functions mainly at the application layer (Layer~7) and typically runs over TCP/IP (Layer~4), which guarantees reliable message delivery.

MQTT’s adjustable Quality of Service (QoS) levels ensure reliability under varying network conditions, while its minimal header size makes it ideal for low-bandwidth or intermittently connected environments—precisely the conditions common at the edge~\cite{hivemq-mqtt-qos, oasis-mqtt-311}. In industrial contexts, MQTT is often integrated with established field protocols such as Modbus (simple request–response communication between PLCs and sensors)~\cite{emqx-modbus-mqtt}. In this paper’s experimental setup, MQTT forms the communication backbone across all three layers.

\subsection{Network topologies and connectivity}

Edge systems combine diverse physical connectivity types to balance range, bandwidth, and energy consumption. This includes short-range Personal Area Networks (PANs) (e.g., Bluetooth, Zigbee) for device linking, Local Area Networks (LANs/Wi-Fi) for local data exchange, and long-range Wide Area Networks (WANs) or LPWAN technologies (e.g., 5G, LoRa) to extend connectivity to remote devices~\cite{iotforall-wireless-protocols}. The ability to manage this heterogeneous network environment, ensuring that the Edge remains autonomous and secure regardless of the connection, is central to the architectural design. Together, these layered protocols and communication paths form the backbone of modern edge infrastructures, linking constrained devices, distributed intelligence and cloud services into a single, adaptive computing continuum.

\section{Layered security and operational management}

Decentralization necessitates a layered security model, as Edge devices are often physically exposed and run without direct supervision. Security begins with hardware resilience, requiring devices to boot only from trusted firmware and use cryptographic validation~\cite{lea-2023-edge-computing}.

Operationally, the focus is on zero-trust models and end-to-end encryption (TLS/SSL) across all network links. Critical to long-term deployment is the ability to manage the device lifecycle, including continuous monitoring, remote diagnostics, and patching, all functions heavily dependent on the orchestration and containerization capabilities of the Edge Cloud layer~\cite{gfg-edge-computing, aws-greengrass-docs}.

For broader context on industrial and cloud-edge security, networking, and operational practices, see additional perspectives from industry and research~\cite{ericsson-edge, mdpi-edge-review, nokia-network-slicing, cloudflare-edge}.